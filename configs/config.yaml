data:
  data_path: "data/News_Category_Dataset_v3.json" # Can be a CSV or JSON file.
  data_class: # The second is the positive class.
    - "not-news"
    - "news"
  class_column: "category" # Column name of the class.
  plot_histograms: true  # Plot histograms of train, val and test sets.
  # Percentage of the data_utils left for validation (rest is for test).
  # If 0.7, 70% of the data_utils is for train, 15% for val and 15% for test.
  train_size: 0.7
  val_size: 0.5

  # If not null, split the text into segments of max_seq_length
  # with overlap of overlap_size words/token. Only for train DF.
  # useful for long texts.
  split_text: null
#  split_text:
#    overlap_size: 50

model:
  # BERT versions: "bert-base-uncased", "bert-base-cased"
  # Smaller versions: "prajjwal1/bert-tiny", "prajjwal1/bert-mini", "prajjwal1/bert-small"
  model_name: "prajjwal1/bert-small"
  uncased: true  # Tokenizer parameter. Bert uncased or cased (case-sensitive)
  freeze_bert: false  # If True, only train the classifier layers.
  linear_layers_num: 1 # Number of linear layers after the BERT model.
  n_classes: 2  # TODO: Support more than 2 classes.
  max_seq_length: 128  # Max sequence length for BERT model.

train:
  num_epochs: 5
  batch_size: 32
  dropout: 0.4
  early_stopping:
    min_delta: 0 # Minimum change in the monitored quantity to qualify as an improvement.
    patience: 2  # Number of epochs with no improvement after which training will be stopped.
  eps: 1.0e-08
  lr: 1.0e-05
  weight_decay: 0.01
  # Samplers are used to specify how to sample from the dataset.
  # "WeightedRandomSampler" - samples with probability proportional to class weights
  #     (larger weights for under-represented classes).
  # "BalancedBatchSampler" - samples batches with equal number of samples from each class.
  # null - samples randomly from the dataset.
  sampler: "WeightedRandomSampler"
